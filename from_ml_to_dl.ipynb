{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04532f20-8b6b-4a86-b8c0-edd00c4f17a0",
   "metadata": {},
   "source": [
    "### 显式（explicit） vs. 隐式（implicit）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925a8473-1c15-48d6-965e-746b4128177a",
   "metadata": {},
   "source": [
    "> 机器学习是显式的，而深度学习是隐式的；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ca47e0-15e5-4999-8c7e-8a78f9a210ba",
   "metadata": {},
   "source": [
    "#### 特征处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2423631-ea2b-42fe-ac1d-dc82d09a2370",
   "metadata": {},
   "source": [
    "  - 显式特征指的是由人工设计和选择的特征。在传统机器学习方法中，如支持向量机（SVM）、决策树、随机森林等，模型的性能在很大程度上依赖于输入数据的特征质量。\n",
    "  - 隐式特征是指由模型自动从数据中学习到的特征。在深度学习中，特别是深层神经网络（如卷积神经网络、循环神经网络等），模型通过多层非线性变换自动提取数据的高层次特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fad0ec-55b6-48b1-bd66-b46b6b090a51",
   "metadata": {},
   "source": [
    "#### 模型表达与复杂度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f447e5-5ab9-4430-bef0-bc0a8d62452e",
   "metadata": {},
   "source": [
    "- 传统经典机器学习（显式）：\n",
    "    - 模型的结构和参数通常较为简单，易于理解和解释。例如，线性回归模型的系数直接反映了各个特征的重要性。\n",
    "    - 这种显式的模型结构使得模型的行为和决策过程更加透明，但也限制了模型表达复杂模式的能力。\n",
    "- 深度学习（隐式）：\n",
    "    - 深度学习模型通过多层网络结构和大量参数，能够表示和学习复杂的函数关系。这种隐式的表达方式使得模型能够捕捉到数据中的复杂和深层次的模式。\n",
    "    - 然而，模型的复杂性也带来了“黑箱”问题，难以解释模型内部的决策过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe02fa9a-8c5a-4c53-a136-3bd521b8372c",
   "metadata": {},
   "source": [
    "### overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b764472-6fcc-4dd8-aba4-5d1c9752c33b",
   "metadata": {},
   "source": [
    "> 过拟合是模型对训练数据的特定噪声或偶然性模式进行了学习，而不是学习到数据的真实底层结构。这导致模型在训练数据上误差很低，但在测试数据或新数据上误差较高。\n",
    "> \n",
    "> memoriation vs. generation\n",
    "\n",
    "- 结果上\n",
    "    - 代表着较弱的泛化能力（generation）；\n",
    "- 数据上，\n",
    "    - 分布不足（一些数据点训练集中没有见过）；\n",
    "        - 甚至记住了细节（局部）和噪声\n",
    "    - 分布不均 -> 容易 overfitting 到更高频的分布上；\n",
    "        - 也就是这些点在 gradient descent 的时候，优化得更多；\n",
    "- 优化\n",
    "    - 学习率和训练轮数：过大的学习率可能导致模型在损失函数表面跳跃，无法收敛；过小的学习率可能使模型陷入局部最小值。过多的训练轮数（epoch）也可能使模型过度拟合训练数据。\n",
    " \n",
    "- loss\n",
    "    - training loss 很低，可以通过 generation 也可以通过 memoriation 实现；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6c355a-7dca-40db-8922-54418eb85bac",
   "metadata": {},
   "source": [
    "### 从监督学习（SL）到无监督学习到强化学习"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35271216-40c1-41e9-88db-ee112de5ed9d",
   "metadata": {},
   "source": [
    "AlphaGo => AlphaGo Zero => AlphaZero (model-free) => MuZero (model-base, 对环境建模)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae2c4cd-fe5e-44d5-8935-9827ce93344e",
   "metadata": {},
   "source": [
    "- AlphaGo\n",
    "    - AlphaGo 是第一个在围棋上击败职业棋手的程序。其核心是结合了 监督学习、强化学习 和 蒙特卡洛树搜索（MCTS）。\n",
    "        - 监督学习预训练：利用大量人类专家的对局数据，训练策略网络 $P_{SL}$，预测下一步的最优落子位置。\n",
    "            - $\\min_\\theta \\mathbb E_{(s,a)\\sim D}[-\\log P_\\theta(a|s)]$\n",
    "            - $D$ 专家对局数据集，$s$ 棋局状态，$a$ 专家选择的动作；\n",
    "        - 强化学习提升：通过自我对弈，进一步训练策略网络 $P_{RL}$，使其超过人类水平。\n",
    "            - $\\min_\\theta \\mathbb E_{s\\sim \\rho_\\theta}[-\\log P_\\theta(a^*|s)]$\n",
    "        - 价值网络训练：训练价值网络 $V$，评估给定棋局的胜率。\n",
    "            - $\\min_\\phi\\mathbb E_{(s,z)\\sim \\rho_\\theta}[(V_\\phi(s)-z)^2]$\n",
    "            - $z$ 是实际对局结果，（胜负平，1,-1,0）\n",
    "        - 蒙特卡洛树搜索：在对弈时，使用策略网络（Policy Network）和价值网络（Value Network）引导 MCTS，提升搜索效率和决策质量。\n",
    "- AlphaGo Zero 完全摒弃了人类专家数据，依赖 强化学习 和 自我对弈。\n",
    "    - 单一神经网络：合并策略网络和价值网络，输出策略向量 $p$ 和状态价值 $v$\n",
    "        - 单一神经网络通过共享的卷积和残差层提取棋局特征，然后分成策略头（policy head）和价值头（value head）两个分支，分别输出策略向量 $p$（$N^2+1$） 和状态价值 $v$（scalar，表示当前棋局对于当前玩家的胜率估计，）\n",
    "    - 自我对弈生成数据：通过当前网络进行自我对弈，生成训练数据。\n",
    "    - 强化学习更新网络：利用自我对弈的数据，更新网络参数。\n",
    "    - 改进的 MCTS：在搜索中融合了神经网络的预测，提高了搜索效率。\n",
    "- AlphaZero：AlphaZero 将 AlphaGo Zero 的方法推广到其他棋类游戏，如国际象棋和将棋。\n",
    "    - 通用性：不依赖特定游戏的先验知识，仅需要游戏规则。\n",
    "    - 强化学习和自我对弈：在不同的游戏中，通过自我对弈和 MCTS，不断提升。\n",
    "    - 统一框架：使用相同的网络结构和训练方法，体现了算法的通用性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c4e200-7af0-49fe-a18e-5bf8e49006b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
