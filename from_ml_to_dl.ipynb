{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04532f20-8b6b-4a86-b8c0-edd00c4f17a0",
   "metadata": {},
   "source": [
    "### 显式（explicit） vs. 隐式（implicit）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925a8473-1c15-48d6-965e-746b4128177a",
   "metadata": {},
   "source": [
    "> 机器学习是显式的，而深度学习是隐式的；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ca47e0-15e5-4999-8c7e-8a78f9a210ba",
   "metadata": {},
   "source": [
    "#### 特征处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2423631-ea2b-42fe-ac1d-dc82d09a2370",
   "metadata": {},
   "source": [
    "  - 显式特征指的是由人工设计和选择的特征。在传统机器学习方法中，如支持向量机（SVM）、决策树、随机森林等，模型的性能在很大程度上依赖于输入数据的特征质量。\n",
    "  - 隐式特征是指由模型自动从数据中学习到的特征。在深度学习中，特别是深层神经网络（如卷积神经网络、循环神经网络等），模型通过多层非线性变换自动提取数据的高层次特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fad0ec-55b6-48b1-bd66-b46b6b090a51",
   "metadata": {},
   "source": [
    "#### 模型表达与复杂度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f447e5-5ab9-4430-bef0-bc0a8d62452e",
   "metadata": {},
   "source": [
    "- 传统经典机器学习（显式）：\n",
    "    - 模型的结构和参数通常较为简单，易于理解和解释。例如，线性回归模型的系数直接反映了各个特征的重要性。\n",
    "    - 这种显式的模型结构使得模型的行为和决策过程更加透明，但也限制了模型表达复杂模式的能力。\n",
    "- 深度学习（隐式）：\n",
    "    - 深度学习模型通过多层网络结构和大量参数，能够表示和学习复杂的函数关系。这种隐式的表达方式使得模型能够捕捉到数据中的复杂和深层次的模式。\n",
    "    - 然而，模型的复杂性也带来了“黑箱”问题，难以解释模型内部的决策过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe02fa9a-8c5a-4c53-a136-3bd521b8372c",
   "metadata": {},
   "source": [
    "### overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b764472-6fcc-4dd8-aba4-5d1c9752c33b",
   "metadata": {},
   "source": [
    "> 过拟合是模型对训练数据的特定噪声或偶然性模式进行了学习，而不是学习到数据的真实底层结构。这导致模型在训练数据上误差很低，但在测试数据或新数据上误差较高。\n",
    "> \n",
    "> memoriation vs. generation\n",
    "\n",
    "- 结果上\n",
    "    - 代表着较弱的泛化能力（generation）；\n",
    "- 数据上，\n",
    "    - 分布不足（一些数据点训练集中没有见过）；\n",
    "        - 甚至记住了细节（局部）和噪声\n",
    "    - 分布不均 -> 容易 overfitting 到更高频的分布上；\n",
    "        - 也就是这些点在 gradient descent 的时候，优化得更多；\n",
    "- 优化\n",
    "    - 学习率和训练轮数：过大的学习率可能导致模型在损失函数表面跳跃，无法收敛；过小的学习率可能使模型陷入局部最小值。过多的训练轮数（epoch）也可能使模型过度拟合训练数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6c355a-7dca-40db-8922-54418eb85bac",
   "metadata": {},
   "source": [
    "### 从监督学习（SL）到无监督学习到强化学习"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35271216-40c1-41e9-88db-ee112de5ed9d",
   "metadata": {},
   "source": [
    "AlphaGo => AlphaGo Zero => AlphaZero (model-free) => MuZero (model-base, 对环境建模)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae2c4cd-fe5e-44d5-8935-9827ce93344e",
   "metadata": {},
   "source": [
    "- AlphaGo\n",
    "    - AlphaGo 是第一个在围棋上击败职业棋手的程序。其核心是结合了 监督学习、强化学习 和 蒙特卡洛树搜索（MCTS）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c4e200-7af0-49fe-a18e-5bf8e49006b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
